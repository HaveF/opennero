#summary Heuristic search exercise on IDA*
#sidebar TableOfContents

=Iterative Deepening `A*` Search=
 
In this exercise, you will be implementing the Iterative Deepening
`A*` (`IDA*`) search algorithm in the OpenNERO platform. You'll use
the existing implementations of Depth First Search (DFS) and `A*`
search as starting points, and modify and extend them to implement
`IDA*`. `IDA*` search is an informed search algorithm that uses the
same heuristic-function strategy as `A*`, but follows a DFS approach
and only keeps track of the most recent path, thus reducing the memory
complexity of the algorithm.


==The OpenNERO Platform==

The following steps should help get you up and running in OpenNERO:

  * Either:
    * Install it on your own machine by downloading one of the [http://code.google.com/p/opennero/downloads/list prebuilt binaries]
    * [BuildingOpenNero Build OpenNERO] on your own machine using the source code.
  * Read the [SystemOverview system overview] to understand the interaction between the platform and the AI agents.
  * Look at the demos for [BruteForceSearch Brute Force] (uninformed) and [HeuristicSearch Heuristic] (informed) search.


==Creating your agent==

To create your `IDA*` agent, open the [http://code.google.com/p/opennero/source/browse/trunk/mods/Maze/agent.py agent.py] file (located in `trunk/mods/Maze`). Notice that there are
several agents implemented here, including a DFS agent
(`DFSSearchAgent`) and an `A*` agent
(`AStarSearchAgent`).

===Agent class===
Create a new class called `IdaStarAgent` with the same code as below:

{{{
class IdaStarSearchAgent(SearchAgent):
    """
    IDA* algorithm
    """
    def __init__(self):
        # this line is crucial, otherwise the class is not recognized as an AgentBrainPtr by C++
        SearchAgent.__init__(self)

    def initialize(self, init_info):
        """
        Initializes the agent upon reset
        """

    def start(self, time, observations):
        """
        Called on the first move
        """
    
    def act(self, time, observations, reward):
        """
        Called every time the agent needs to take an action
        """

    def end(self, time, reward):
        """
        at the end of an episode, the environment tells us the final reward
        """
        print  "Final reward: %f, cumulative: %f" % (reward[0], self.fitness[0])
        self.reset()
        return True

    def destroy(self):
        """
        After one or more episodes, this agent can be disposed of
        """
        return True
}}}

Your agent is operating in a 2-D maze and is capable of moving from cell to cell. In the `start` and `act` methods, your agent receives a collection of `observations` about the world:

  * `observations[0]` -- The current row position of your agent.
  * `observations[1]` -- The current column position of your agent.
  * `observations[2]` -- 1 if there is an obstacle in the row above your position, otherwise 0.
  * `observations[3]` -- 1 if there is an obstacle in the row below your position, otherwise 0.
  * `observations[4]` -- 1 if there is an obstacle in the column to the right of your position, otherwise 0.
  * `observations[5]` -- 1 if there is an obstacle in the column to the left of your position, otherwise 0.

In these methods, you are required to return an `action` -- an integer corresponding to the desired move:

  * 0 -- Move to the row above. `(row, column) → (row + 1, column)`
  * 1 -- Move to the row below. `(row, column) → (row - 1, column)`
  * 2 -- Move to the column to the right. `(row, column) → (row, column + 1)`
  * 3 -- Move to the column to the left. `(row, column) → (row, column - 1)`
  * 4 -- Do nothing.

The class above is an empty skeleton. Refer to the other agent implementations in `agent.py` for guidance on how to implement in your agent. 

===Configuration file===

Once you've created your agent, you'll need to add it to the configuration file for the OpenNERO maze mod. To do this, locate the SydneyAStar.xml file (`Maze/data/shapes/character/SydneyAStar.xml`) and change the following line:

{{{
<Python agent="Maze.agent.AStarSearchAgent()">
}}}

to:

{{{
<Python agent="Maze.agent.IdaStarSearchAgent()">
}}}

Once you've configured this line, pressing the `Single Agent A*` button in the Maze mod will run your agent.

===Debugging===

If you run into any bugs in your program, you can find the error log file for OpenNERO at one of the following locations:

  * *Linux or Mac:* `~/.opennero/nero_log.txt`
  * *Windows:* `"AppData\Local\OpenNERO\nero_log.txt"` or `"Local Settings\Application Data\OpenNERO\nero_log.txt"` depending on the version of Windows you have.