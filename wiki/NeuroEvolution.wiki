#summary NeuroEvolution demo
#labels Demo
#sidebar TableOfContents

<wiki:toc />

=Introduction=

[http://nn.cs.utexas.edu/?miikkulainen:encyclopedia10-ne Neuroevolution] is a method for modifying neural network weights, topologies, or ensembles in order to learn a specific task. Evolutionary computation is used to search for network parameters that maximize a fitness function that measures performance in the task. Compared to other neural network learning methods, neuroevolution is highly general, allowing learning without explicit targets, with nondifferentiable activation functions, and with recurrent networks. It can also be combined with standard neural network learning to e.g. model biological adaptation. Neuroevolution can also be seen as a policy search method for reinforcement-learning problems, where it is well suited to continuous domains and to domains where the state is only partially observable.

OpenNERO includes several demonstrations of the [http://nn.cs.utexas.edu/?NEAT NEAT] ([http://nn.cs.utexas.edu/?rtNEAT rtNEAT]) algorithm. NEAT is an evolutionary algorithm and adapts the weights and the topologies of neural network controllers.

=Evolving a maze agent=

MazeMod includes the ability to evolve an agent to navigate the maze. After starting the mod, select the *Neuroevolution* button.

=Evolution in the NERO mod=

Like the [http://www.nerogame.org NERO game], NeroMod is built around evolving a population of agents for a variety of tasks. 

After starting the *NERO* mod, set the desired fitness sliders and click *Deploy*. Sliders can be adjusted during the training process to shape the agents via their fitness function.

=Evolving a cleaning robot=

In the RoombaMod, select the *rtNEAT* agents and click *Add Bots* to have them evolve a better cleaning strategy.