#summary This page describes the core API for OpenNERO agents and environments.
#sidebar TableOfContents

OpenNERO is a federation of several _mods_ - nearly independent
collections of resources and scripts stored in individual directories.
For example, there are the [MazeMod Maze mod], the [NeroMod NERO mod] 
and the [RoombaMod Roomba mod] - see [RunningOpenNero Running OpenNERO]
for more details.

Since OpenNERO is all about designing intelligent agents, it has an 
API for adding new _agents_ and new _environments_ to test them in. 
An agent can interact with an environment by receiving _observations_ 
from it, sending it _actions_, and receiving _rewards_ for those 
actions. Agents in OpenNERO extend the class `AgentBrain`. 
Environments extend the `Environment` class. Both agents and 
environments can be written in Python or in C++.

<img src=http://opennero.googlecode.com/svn/wiki/agent-environment-loop.png height=300 width=400></img>

The main interfaces (which are defined in C++ and exported into Python) look like this:

===[http://code.google.com/p/opennero/source/browse/trunk/source/ai/Environment.h Environment]===
  * *sense*(agent): `Observations` <font color=green>// produce the observations that the agent 'sees'</font>
  * *step*(agent, action): `Reward` <font color=green>// perform the action requested by the agent and return the reward</font> 
  * *get_agent_info*(agent): `AgentInitInfo` <font color=green>// return the initialization information describing the state and action spaces for the agent</font>
  * *is_episode_over*(agent): boolean <font color=green>// return true iff the episode is over for the agent</font>
  * *cleanup*(agent) <font color=green>// clean up the environment before exiting</font>
  * *reset*(agent) <font color=green>// return the environment to its initial state</font>

===[http://code.google.com/p/opennero/source/browse/trunk/source/ai/AgentBrain.h AgentBrain]===
  * *initialize*(agent_init_info) <font color=green>// initialize the agent with the `AgentInitInfo` from the environment</font>
  * *start*(time, observations): `Actions` <font color=green>// determine the first action the agent should take given its initial observations</font>
  * *act*(time, observations, reward): `Actions` <font color=green>// determine the consequent actions the agent should take given the observations</font>
  * *end*(time, observations, reward) <font color=green>// get information about the final observation and reward from the environment</font>
  * *destroy*() <font color=green>// destroy the agent and release its resources</font>

===`AgentInitInfo`, `Actions` and `Observations`===

The basic types OpenNERO uses to pass around information between `Environment` and `Agent` are defined in [http://code.google.com/p/opennero/source/browse/trunk/source/ai/AI.h AI.h]. Both `Actions` and `Observations` are actually a `FeatureVector` - an array of one or more double values. Conceptually, a `FeatureVector` carries discrete or continuous values within a certain range. In order to describe the possible values for a particular `FeatureVector`, a `FeatureVectorInfo` is used:

===`AgentInitInfo`===
  * *sensors*: `FeatureVectorInfo` <font color=green>// description of the state (observation) space</font>
  * *actions*: `FeatureVectorInfo` <font color=green>// description of the action space</font>
  * *rewards*: `FeatureVectorInfo` <font color=green>// description of the rewards</font>

===`FeatureVectorInfo`===
  * *size*(): integer <font color=green>// number of elements in the vector</font>
  * *addDiscrete*(min, max): integer <font color=green> // add a discrete feature</font>
  * *addContinuous*(min, max): integer <font color=green> // add a continuous feature</font>
  * *getBounds*(i): `Bounds` <font color=green> // get the bounds of the ith feature</font>
  * *getMin*(i): double <font color=green>// min of ith element</font>
  * *getMax*(i): double <font color=green>// max of ith element</font>
  * *isDiscrete*(i): boolean <font color=green>// return true iff the ith feature is discrete</font>
  * *isContinuous*(i): boolean <font color=green>// return true iff the ith feature is continous</font>
  * *validate*(feature_vector): boolean <font color=green>// check that feature_vector is in compliance with these bounds</font>
  * *getInstance*(): `FeatureVector` <font color=green>// get a zero instance of this feature vector</font>
  * *getRandom*(): `FeatureVector` <font color=green>// get a random instance of this feature vector</font>

== Agent-Environment interaction diagram ==

<img src=http://opennero.googlecode.com/svn/wiki/agent-environment-sequence.png height=864 width=553></img>
(Generated using [http://www.websequencediagrams.com/] from diagram text:
{{{
note left of Environment: get_init_info()
Environment->Agent: AgentInitInfo info
note right of Agent: initialize(info)
note left of Environment: sense()
Environment->Agent: Observations O
note right of Agent: start(O)
Agent->Environment: Actions A
loop until is_episode_over
  note left of Environment: sense(), step(A)
  Environment->Agent: Observations O, Reward R
  note right of Agent: act(O,R), is_episode_over?
  Agent->Environment: Actions A, False
end
note left of Environment: sense(), step(A)
Environment->Agent: Observations O, Reward R
note right of Agent: act(O,R), is_episode_over?
Agent->Environment: Actions A, True
note left of Environment: sense(), step(A)
Environment->Agent: Observations O, Reward R
note right of Agent: end(O,R)
}}}